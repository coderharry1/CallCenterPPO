# ğŸ“ Optimising Call Centre Operations with Reinforcement Learning (PPO)

**University of Adelaide â€“ Masterâ€™s Final Year Project**  
*Supervisor: Dr. Wathsala Karunarathne*  

---

## ğŸš€ Project Overview  

Traditional call centre routing systems rely on **static, rule-based allocation**, often leading to:  
- â³ Longer wait times  
- âŒ Lower first-call resolution rates  
- ğŸ˜¡ Declining customer satisfaction  

This project builds a **Reinforcement Learning (RL)**-based solution using **Proximal Policy Optimisation (PPO)** to dynamically assign calls to agents. Unlike static rules, the RL agent continuously adapts to:  
- Real-time queue conditions  
- Agent expertise and availability  
- Call complexity and topic variation  

---

## ğŸ”‘ Key Results  

âœ… **18% improvement** in customer satisfaction  
âœ… **15% increase** in first-call resolution rates  
âœ… Average wait time reduced to **54.5s** (vs. 67s baseline)  
âœ… Maintained strong performance during **peak call loads**  
âœ… Achieved improvements **without extra staffing costs**  

âš¡ *This proves reinforcement learning can optimise large-scale service systems in the real world.*  

---

## ğŸ› ï¸ Technical Stack  

- **Languages:** Python (Pandas, NumPy, Scikit-learn)  
- **RL Frameworks:** PyTorch, Stable Baselines3  
- **Simulation:** Custom **OpenAI Gym environment** (CallCenterEnv)  
- **Visualisation:** Matplotlib, Seaborn  
- **Data:** 10,000+ historical call centre records (ModifiedCallCenter.xlsx)  

---

## ğŸ§  Methodology  

1. **Data Engineering**  
   - Cleaned 10k+ call logs  
   - Engineered features: *Call Congestion Index, Hourly Call Trends, Agent Performance Tiers*  

2. **Environment Design**  
   - Built a custom **Gym-compatible environment** simulating queue lengths, call topics, and agent efficiency  

3. **Reward Function**  
   - Balanced **wait time, resolution success, satisfaction scores, agent-topic match**  

4. **PPO Agent Training**  
   - Actor-Critic networks (2Ã—256 units, ReLU)  
   - Trained for **200+ episodes**  
   - Tuned hyperparameters (Î³=0.99, Î»=0.95, Îµ=0.2, lr=3e-4)  

5. **Evaluation**  
   - Benchmarked against rule-based routing  
   - Tested across peak hours & topic complexities  

---

## ğŸ“Š Performance Summary  

| Metric                        | Baseline | PPO Agent | Î” Improvement |
|-------------------------------|----------|-----------|---------------|
| Avg Wait Time (sec)           | 67       | **54.5**  | â†“ 19% |
| First Call Resolution (FCR)   | 0.63     | **0.73**  | +15% |
| Customer Satisfaction (1â€“5)   | 2.5      | **2.95**  | +18% |
| 90th Percentile Wait (sec)    | 140      | **111**   | â†“ 21% |

---
## ğŸ“ˆ Key Visuals  
![Wait Time Reduction](<img width="347" height="185" alt="Screenshot 2025-08-25 at 11 41 55â€¯AM" src="https://github.com/user-attachments/assets/afeae65d-8016-4894-92dd-ece1955dad53" />
)  
![Agent Satisfaction Heatmap](<img width="317" height="213" alt="Screenshot 2025-08-25 at 11 44 35â€¯AM" src="https://github.com/user-attachments/assets/8a607289-1a9a-47bd-9f1e-10142ef68842" />
)  

## ğŸŒ Business Impact  

- **Customer Experience** â†’ Faster response + higher satisfaction â†’ stronger retention.  
- **Operational Efficiency** â†’ Better agent allocation without new hires.  
- **Scalability** â†’ PPO adapts to real-time spikes (weekends, seasonal campaigns).  
- **Transferability** â†’ Approach generalises to *banking hotlines, healthcare helplines, and IT service desks*.  

---

## ğŸ“‚ Repository Structure  

```
â”œâ”€â”€ CallCenterPPO.ipynb      # Full training + evaluation notebook
â”œâ”€â”€ environment.py           # Custom OpenAI Gym call centre environment
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ModifiedCallCenter.xlsx   # Call centre dataset
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ training_rewards.png
â”‚   â”œâ”€â”€ wait_time_reduction.png
â”‚   â””â”€â”€ agent_heatmap.png
â””â”€â”€ README.md                # This file
```

---

## â–¶ï¸ How to Run  

```bash
# Clone repo
git clone https://github.com/coderharry1/CallCenterPPO.git
cd CallCenterPPO

# Install dependencies
pip install -r requirements.txt

# Run PPO training
python CallCenterPPO.ipynb
```

---

## ğŸ“Œ Future Directions  

- Add **customer segmentation** for personalised routing  
- Deploy prototype in **cloud-native environments (AWS / GCP)**  
- Extend to **multi-agent reinforcement learning** for distributed call centres  

---

## ğŸ™ Acknowledgements  

Special thanks to **Dr. Wathsala Karunarathne** for her guidance in reinforcement learning and optimisation, and to the University of Adelaideâ€™s **School of Mathematical Sciences** for academic support.  
---

## ğŸ”— Links  
ğŸ‘‰ Explore the full code + training logs here: [CallCenterPPO.ipynb](https://github.com/coderharry1/CallCenterPPO/blob/main/CallCenterPPO.ipynb)
